ğŸ¤– RAG Chatbot â€“ PDF & Web Scraping

A Retrieval-Augmented Generation (RAG) chatbot built with Streamlit that allows users to chat only from provided PDF documents or scraped web content.
The chatbot uses Groqâ€™s high-performance LLMs along with vector search to deliver accurate, hallucination-free responses.

âœ¨ Features

ğŸ“„ PDF Document Processing
Upload PDF files and ask questions directly from the document content.

ğŸŒ Web Scraping Support
Scrape website content and interact with the extracted information.

ğŸ’¬ Interactive Chat Interface
User-friendly Streamlit interface for natural conversations.

ğŸ” Vector-Based Retrieval
Efficient semantic search using FAISS and HuggingFace embeddings.

ğŸš€ Powered by Groq LLMs
Ultra-fast inference using models like LLaMA 3.1 and Mixtral.

ğŸ”§ Highly Configurable
Control model selection, temperature, chunk size, and retrieval depth.

ğŸ› ï¸ Technologies Used

Streamlit â€“ Web application interface

LangChain â€“ Document processing and orchestration

FAISS â€“ Vector database for similarity search

HuggingFace â€“ Embeddings (all-MiniLM-L6-v2)

Groq â€“ LLM inference engine

BeautifulSoup â€“ Web scraping

PyPDF â€“ PDF document parsing

ğŸ“¦ Installation
1ï¸âƒ£ Clone the Repository
git clone <your-repo-url>
cd rag-chatbot

2ï¸âƒ£ Create a Virtual Environment (Recommended)
Windows
python -m venv venv
venv\Scripts\activate

macOS / Linux
python3 -m venv venv
source venv/bin/activate

3ï¸âƒ£ Install Dependencies
Option 1: Install manually
pip install streamlit
pip install langchain-community langchain-core langchain-text-splitters
pip install pypdf faiss-cpu sentence-transformers
pip install groq requests beautifulsoup4 python-dotenv

Option 2: Install from requirements.txt
pip install -r requirements.txt

ğŸ”‘ Environment Setup
1ï¸âƒ£ Create .env file
cp .env.example .env

2ï¸âƒ£ Add your Groq API Key
GROQ_API_KEY=your_actual_groq_api_key_here


ğŸ”— Get your API key from:
https://console.groq.com/keys

â–¶ï¸ Run the Application
streamlit run app.py


The app will open at:
ğŸ‘‰ http://localhost:8501

ğŸ”§ Configuration

All configuration is managed using the .env file.

ğŸ” Required Configuration
Variable	Description
GROQ_API_KEY	Your Groq API key

ğŸ§  Model Configuration
Variable	Default	Description
MODEL_NAME	llama-3.1-8b-instant	LLM model
TEMPERATURE	0	Controls randomness (0â€“1)
MAX_COMPLETION_TOKENS	1024	Max response length

ğŸ“Š Embedding Configuration
Variable	Default	Description
EMBEDDING_MODEL	all-MiniLM-L6-v2	HuggingFace embedding model

âœ‚ï¸ Text Processing Configuration
Variable	Default	Description
CHUNK_SIZE	1000	Characters per chunk
CHUNK_OVERLAP	200	Overlap between chunks

ğŸ” Retrieval Configuration
Variable	Default	Description
RETRIEVAL_K	3	Number of chunks retrieved

ğŸŒ Web Scraping Configuration
Variable	Default	Description
DEFAULT_SCRAPE_URL	https://www.icmr.gov.in/tenders	Default URL
SCRAPE_TIMEOUT	10	Request timeout (seconds)
MIN_TEXT_LENGTH	30	Minimum text length

ğŸš€ Usage
ğŸ“„ PDF Mode

Select PDF Upload from the sidebar
Upload a PDF file
Click Process PDF
Ask questions from the document

ğŸŒ Web Scraping Mode

Select Website Scraping
Enter a URL (or use default)
Click Scrape Website
Ask questions from scraped content

âš™ï¸ Advanced Settings

Use the sidebar to adjust:
Temperature (creativity control)
Max response tokens
Retrieval depth (K value)

ğŸ§  Key Design Principle

The chatbot strictly answers only from the provided documents and web sources, ensuring high accuracy and zero hallucination.

ğŸ“Œ Future Improvements (Optional)

Multi-PDF support

Chat history persistence

Source citation highlighting

Cloud deployment (Streamlit Community Cloud)

â­ Final Note

This project demonstrates a production-ready RAG pipeline combining document intelligence, vector search, and LLM inference â€” suitable for enterprise, research, and knowledge-base applications.
